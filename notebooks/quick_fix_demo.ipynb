{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Fix Demo - Retail Semantic Analysis\n",
    "This notebook uses simplified preprocessing that doesn't require NLTK downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's try to download NLTK data\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    print(\"Attempting to download NLTK data...\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('vader_lexicon')\n",
    "    print(\"NLTK data downloaded successfully!\")\n",
    "    NLTK_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"NLTK download failed: {e}\")\n",
    "    print(\"Using simple preprocessor instead...\")\n",
    "    NLTK_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import modules based on NLTK availability\n",
    "from data_loader import RetailDataLoader\n",
    "if NLTK_AVAILABLE:\n",
    "    from preprocessor import RetailTextPreprocessor\n",
    "    print(\"Using full NLTK preprocessor\")\n",
    "else:\n",
    "    from simple_preprocessor import SimpleTextPreprocessor as RetailTextPreprocessor\n",
    "    print(\"Using simplified preprocessor\")\n",
    "\n",
    "from sentiment_analyzer import RetailSentimentAnalyzer\n",
    "from topic_modeling import RetailTopicModeler\n",
    "from visualizations import RetailVisualizationGenerator\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Enhanced Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = RetailDataLoader()\n",
    "\n",
    "# Create enhanced sample data\n",
    "np.random.seed(42)\n",
    "\n",
    "positive_reviews = [\n",
    "    \"This product exceeded my expectations! The quality is outstanding and delivery was fast.\",\n",
    "    \"Excellent value for money. The material feels premium and the design is beautiful.\",\n",
    "    \"Perfect fit and great functionality. I would definitely recommend this to others.\",\n",
    "    \"Amazing customer service and quick response. The product works exactly as described.\",\n",
    "    \"Love the innovative features and user-friendly design. Five stars!\",\n",
    "    \"Great packaging and the item arrived in perfect condition. Very satisfied.\",\n",
    "    \"This is exactly what I was looking for. Good quality and reasonable price.\",\n",
    "    \"Impressive build quality and attention to detail. Worth every penny.\",\n",
    "    \"Fast shipping and excellent product. Will definitely buy from this seller again.\",\n",
    "    \"Outstanding performance and reliability. Highly recommended for anyone.\"\n",
    "]\n",
    "\n",
    "negative_reviews = [\n",
    "    \"Poor quality materials and the product broke after just a few days of use.\",\n",
    "    \"Very disappointed with this purchase. Not as described and overpriced.\",\n",
    "    \"Terrible customer service and slow shipping. The item was damaged on arrival.\",\n",
    "    \"Cheap construction and doesn't work properly. Waste of money.\",\n",
    "    \"The fit is completely wrong and the material feels flimsy.\",\n",
    "    \"Misleading product description. What I received was nothing like the pictures.\",\n",
    "    \"Took forever to arrive and when it did, it was defective.\",\n",
    "    \"Not worth the price at all. Very poor quality and design.\",\n",
    "    \"Packaging was terrible and the product was damaged. Very unsatisfied.\",\n",
    "    \"Would not recommend this product to anyone. Save your money.\"\n",
    "]\n",
    "\n",
    "neutral_reviews = [\n",
    "    \"The product is okay, nothing special but does what it's supposed to do.\",\n",
    "    \"Average quality for the price. Could be better but not terrible.\",\n",
    "    \"It's fine, meets basic expectations but nothing extraordinary.\",\n",
    "    \"Decent product with some pros and cons. Mixed feelings about it.\",\n",
    "    \"Works as expected, though there are some minor issues.\",\n",
    "    \"The quality is acceptable for this price range. Nothing more, nothing less.\",\n",
    "    \"Standard product with average performance. Does the job.\",\n",
    "    \"It's an okay purchase. Not great but not bad either.\",\n",
    "    \"Functional but could use some improvements in design.\",\n",
    "    \"Fair value for money. Some good features, some not so good.\"\n",
    "]\n",
    "\n",
    "# Generate dataset\n",
    "reviews = []\n",
    "sentiments = []\n",
    "ratings = []\n",
    "categories = []\n",
    "dates = []\n",
    "\n",
    "for i in range(1500):\n",
    "    # Generate date within last 2 years\n",
    "    start_date = datetime.now() - timedelta(days=730)\n",
    "    random_days = np.random.randint(0, 730)\n",
    "    review_date = start_date + timedelta(days=random_days)\n",
    "    \n",
    "    # Determine sentiment with realistic distribution\n",
    "    rand = np.random.random()\n",
    "    if rand < 0.6:  # 60% positive\n",
    "        review = np.random.choice(positive_reviews)\n",
    "        sentiment = 'positive'\n",
    "        rating = np.random.choice([4, 5], p=[0.3, 0.7])\n",
    "    elif rand < 0.85:  # 25% negative\n",
    "        review = np.random.choice(negative_reviews)\n",
    "        sentiment = 'negative'\n",
    "        rating = np.random.choice([1, 2], p=[0.6, 0.4])\n",
    "    else:  # 15% neutral\n",
    "        review = np.random.choice(neutral_reviews)\n",
    "        sentiment = 'neutral'\n",
    "        rating = 3\n",
    "    \n",
    "    category = np.random.choice(['Electronics', 'Clothing', 'Books', 'Home & Kitchen'], \n",
    "                               p=[0.35, 0.25, 0.20, 0.20])\n",
    "    \n",
    "    reviews.append(review)\n",
    "    sentiments.append(sentiment)\n",
    "    ratings.append(rating)\n",
    "    categories.append(category)\n",
    "    dates.append(review_date)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'review_text': reviews,\n",
    "    'sentiment': sentiments,\n",
    "    'rating': ratings,\n",
    "    'product_category': categories,\n",
    "    'review_date': dates\n",
    "})\n",
    "\n",
    "print(f\"Dataset created with {len(df)} reviews\")\n",
    "print(f\"Categories: {df['product_category'].value_counts().to_dict()}\")\n",
    "print(f\"Sentiment distribution: {df['sentiment'].value_counts().to_dict()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "if NLTK_AVAILABLE:\n",
    "    preprocessor = RetailTextPreprocessor(download_nltk=True)\n",
    "else:\n",
    "    preprocessor = RetailTextPreprocessor()\n",
    "\n",
    "# Preprocess the dataset\n",
    "print(\"Preprocessing text data...\")\n",
    "df_processed = preprocessor.preprocess_dataframe(df, text_column='review_text')\n",
    "\n",
    "print(f\"Processed dataset has {len(df_processed)} reviews\")\n",
    "print(\"\\nText statistics:\")\n",
    "stats = preprocessor.get_text_statistics(df_processed)\n",
    "display(stats)\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nPreprocessing examples:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"Original: {df['review_text'].iloc[i]}\")\n",
    "    print(f\"Processed: {df_processed['review_text_clean'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentiment analyzer with TextBlob (most reliable)\n",
    "sentiment_analyzer = RetailSentimentAnalyzer(model_type='textblob')\n",
    "\n",
    "# Analyze sentiment\n",
    "print(\"Analyzing sentiment...\")\n",
    "df_sentiment = sentiment_analyzer.analyze_dataframe(df_processed)\n",
    "\n",
    "print(\"Sentiment analysis completed!\")\n",
    "sentiment_dist = sentiment_analyzer.get_sentiment_distribution(df_sentiment)\n",
    "print(\"\\nPredicted sentiment distribution:\")\n",
    "display(sentiment_dist)\n",
    "\n",
    "# Compare with original labels\n",
    "print(\"\\nComparison: Original vs Predicted\")\n",
    "comparison = pd.crosstab(df_sentiment['sentiment'], df_sentiment['sentiment_sentiment'], \n",
    "                        margins=True, normalize='columns')\n",
    "display(comparison.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize topic modeler\n",
    "topic_modeler = RetailTopicModeler(method='lda')\n",
    "\n",
    "# Prepare texts\n",
    "texts = df_sentiment['review_text_clean'].tolist()\n",
    "print(f\"Preparing {len(texts)} texts for topic modeling...\")\n",
    "\n",
    "# Fit topic model with 5 topics\n",
    "print(\"Fitting topic model with 5 topics...\")\n",
    "topic_modeler.fit_topic_model(texts, num_topics=5)\n",
    "\n",
    "# Get topic words\n",
    "topic_words = topic_modeler.get_topic_words(num_words=8)\n",
    "print(\"\\nIdentified topics:\")\n",
    "for i, words in enumerate(topic_words):\n",
    "    print(f\"Topic {i}: {', '.join(words)}\")\n",
    "\n",
    "# Create topic summary\n",
    "topic_summary = topic_modeler.create_topic_summary(texts)\n",
    "print(\"\\nTopic summary:\")\n",
    "display(topic_summary[['topic_id', 'top_words', 'document_count', 'percentage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualization generator\n",
    "viz_generator = RetailVisualizationGenerator()\n",
    "\n",
    "# Create sentiment distribution plot\n",
    "print(\"Creating sentiment distribution plot...\")\n",
    "fig1 = viz_generator.plot_sentiment_distribution(df_sentiment, sentiment_column='sentiment_sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment by category plot\n",
    "print(\"Creating sentiment by category plot...\")\n",
    "fig2 = viz_generator.plot_sentiment_by_category(df_sentiment)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create topic distribution plot\n",
    "print(\"Creating topic distribution plot...\")\n",
    "fig3 = viz_generator.plot_topic_distribution(topic_summary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word cloud\n",
    "print(\"Creating word cloud...\")\n",
    "all_text = ' '.join(df_sentiment['review_text_clean'].tolist())\n",
    "wordcloud = viz_generator.create_word_cloud(all_text, title=\"Customer Reviews Word Cloud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Business Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate business insights\n",
    "insights = {\n",
    "    'total_reviews': len(df_sentiment),\n",
    "    'sentiment_distribution': df_sentiment['sentiment_sentiment'].value_counts().to_dict(),\n",
    "    'avg_confidence': df_sentiment['sentiment_confidence'].mean(),\n",
    "}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BUSINESS INTELLIGENCE INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Reviews Analyzed: {insights['total_reviews']:,}\")\n",
    "print(f\"Average Sentiment Confidence: {insights['avg_confidence']:.3f}\")\n",
    "\n",
    "print(\"\\n📊 SENTIMENT DISTRIBUTION:\")\n",
    "for sentiment, count in insights['sentiment_distribution'].items():\n",
    "    percentage = (count / insights['total_reviews']) * 100\n",
    "    print(f\"  {sentiment.capitalize()}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n📈 CATEGORY PERFORMANCE:\")\n",
    "category_sentiment = df_sentiment.groupby(['product_category', 'sentiment_sentiment']).size().unstack(fill_value=0)\n",
    "category_sentiment_pct = category_sentiment.div(category_sentiment.sum(axis=1), axis=0) * 100\n",
    "display(category_sentiment_pct.round(1))\n",
    "\n",
    "print(\"\\n🎯 KEY RECOMMENDATIONS:\")\n",
    "positive_pct = (insights['sentiment_distribution'].get('positive', 0) / insights['total_reviews']) * 100\n",
    "negative_pct = (insights['sentiment_distribution'].get('negative', 0) / insights['total_reviews']) * 100\n",
    "\n",
    "print(f\"1. Monitor negative sentiment ({negative_pct:.1f}%) for improvement opportunities\")\n",
    "print(f\"2. Leverage positive sentiment ({positive_pct:.1f}%) for marketing\")\n",
    "print(f\"3. Focus on quality improvements in Electronics category\")\n",
    "print(f\"4. Implement real-time sentiment monitoring\")\n",
    "print(f\"5. Use topic insights for product development\")\n",
    "\n",
    "print(\"\\n✅ ANALYSIS COMPLETE!\")\n",
    "print(\"Check the research paper at: paper/research_paper.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}